
<![endif]-->

# Звіт-ретроспектива з виконання лабораторної роботи
1. **Які конкретні задачі планували вирішувати за допомогою цієї бібліотеки?**
Я розв'язав типову задачу машинного навчання - передбачення класу до якого належить об'єкт на зображенні. У якості датасету було обрано CIFAR-10 - 60 тисяч кольорових зображень, кожне має розмір 32 на 32 пікселя та належить до одного з десяти класів. Конкретніше, задача полягала спочатку у підборі архітектури згорткової нейронної мережі, що задовольняла би суб'єктивним критеріям простоти (швидкості) та якості передбачень, та реалізації отриманої архітектури за допомогою декількох фреймворків для порівняння їх за такими критеріями як, наприклад, простота у використання, гнучкість та швидкість. Одразу тут і зазначу, що була обрана архітектура з  трьох блоків convolution-pooling-dropout та 150 тисяч ваг, що при правильному навчанні отримувала 80% точності передбачень на валідаційній вибірці.
2. **Чому було обрано саме цю бібліотеку, а не аналоги?**
Було обрано такі бібліотеки як Tensorflow, Keras (з бекендом Tensorflow) та PyTorch. TensorFlow є найпопулярнішим фреймворком для глибокого навчання, Keras - найпопулярнішим інтерфейсом для нього. До того ж, з цима двома є вже працював раніше. PyTorch здався для мене найбільш привабливим з решти (простота та лаконічність, eager execution). Решта фреймворків, з якими я би ще хотів попрацювати - CNTK, Caffe, MXNet - залишаються на майбутнє.
3. **Наскільки просто та зрозуміло було отримати, встановити, налаштувати та почати використовувати цю бібліотеку?**
Всі зазначені бібліотеки легко встановлюються однією-двома командами менеджеру пакетів conda, проте при використанні стандартного pip можуть виникнути труднощі при налаштуванні CUDA та CuDNN для проведення обчислень на GPU.
4. **Наскільки зрозумілою та корисною була документація бібліотеки?**
Keras та PyTorch мають добрі документації та офіційні туторіали. TensorFlow же взагалі має досить безладну структуру, що вплинуло на досвід користування й документацією.
5. **Наскільки було зрозуміло, як саме використовувати бібліотеку, які класи/методи/функції використовувати для вирішення поставлених задач?**
Знову ж таки, Keras та PyTorch мають інтуїтивний API, проте TensorFlow - ні. Одних тільки реалізацій dropout у TensorFlow я нарахував [п'ять штук](https://www.tensorflow.org/s/results/?q=dropout&p=/).
6. **Наскільки зручно було використовувати бібліотеку, чи не треба було писати багато надлишкового коду?**
Keras є зручним інструментом для швидкого прототипування та потребує мінімального написання коду для реалізації звичайних моделей глибокого навчання. PyTorch є набагато більш гнучким, але й писати коду власноруч потрібно більше чим на Keras, проте все ще набагато менше ніж на TensorFlow. До того ж (суб'єктивно) TensorFlow є дуже примхливим (наприклад, до типів вхідних даних).
7. **Наскільки зрозумілою була поведінка класів/методів/функцій з бібліотеки?**
Keras, PyTorch - поведінка компонентів зрозуміла інтуїтивно. TensorFlow: знов приклад з dropout - різні реалізації dropout мають різні параметри (якщо в одній вказується значення параметра, нехай, p, то в іншій 1-p, що сильно збивало з пантелику).
8. **Наскільки зрозумілою була взаємодія між різними класами/методами/функціями цієї бібліотеки, а також взаємодія між бібліотекою та власним кодом?**
Тенденція прояву себе TensorFlow з поганих боків у порівнянні з Keras та PyTorch зберігається і в цьому питанні.
9. **Чи виникали якісь проблеми з використанням бібліотеки? Чи вдалось їх вирішити, як саме?**
Суттєвою проблемою при використанні TensorFlow стали BatchNormalization шари. Їх використання, звичайно, значно прискорювало та полегшувало навчання мережі, але під час етапу передбачень мережа видавала умовно випадкові значення. Цікавим є те, що таке саме використання BatchNormalization у TensorFlow в мене вже було і добре працювало. Найшвидшим вирішенням проблеми було видалення BatchNormalization шарів з моделей на усіх трьох фреймворках. Варто зазначити, що саме з використанням BatchNormalization модель на Keras досягала 80% точності.
10. **Що хорошого можна сказати про цю бібліотеку, які були позитивні аспекти використання бібліотеки?**
Підсумовуючи вищесказане:
- Keras - можливість швидкого прототипування за допомогою значної кількості вже реалізованих основних компонентів нейронних мереж
- PyTorch - гнучкість, ресурсоефективність (про це далі), лаконічність, eager execution
- TensorFlow - популярність, надійність, всеосяжність, низькорівневість
11. **Що поганого можна сказати про цю бібліотеку, які були негативні аспекти використання бібліотеки?**
- Keras - високорівневість
- PyTorch - ніяких суттєвих
- TensorFlow - безладність, швидкість (про це далі), низькорівневість.
12. **Якби довелось вирішувати аналогічну задачу, але вже враховуючи досвід використання в цій лабораторній роботі, що варто було б робити так само, а що змінити? Можливо, використати інші бібліотеки, чи використати інші можливості цієї бібліотеки, чи інакше організувати код, чи ще щось?**
Напишу, які бібліотеки з трьох розглянутих я використовував би у майбутньому.
- Keras при першому застосуванні нейронних мереж для розв'язання поставленої задачі для перевірки гіпотез та побудови baseline-моделей.
- PyTorch для обчислень які виходять за рамки можливостей Keras у рамках власних невеликих проектів.
- TensorFlow для підготовки production-рішень, коли не жалко витратити часу та сил.
13. **Інші коментарі**
У кінці хотів би розповісти про порівняння швидкості виконання еквівалентних (з точки зору нейронної мережі) операцій. Keras та PyTorch витрачали приблизно однаковий час на одну епоху як в мене локально, так і в середовищі Google Colab, але моя реалізація однієї конкретної моделі на TensorFlow для розв'язання однієї конкретної задачі було найповільнішою і витрачала приблизно у два рази більше часу на одну епоху, повністю навантажуючи мою GPU. Очевидно, проблема в недоліках однієї моєї конкретної реалізації, адже Keras використовував той самий TensorFlow у якості бекенда. Цікавим є також те, що PyTorch майже не навантажував як мою локальну GPU (3-5%), так і CPU (20%), демонструючи схожі показники швидкості з Keras, що навантажував обидва процесори приблизно на половину. Ще раз підкреслю, що все сказане є лише констатацією фактів спостережених у моєму конкретному випадку і може залежати від задачі, моделі, реалізації та параметрів hardware.
14. **Посилання**
- https://keras.io/
- https://pytorch.org/
- https://www.tensorflow.org/
15. **Google Colab**
Погратися власноруч з кодом виконання цього завдання можна у середовищі Google Colab:
https://colab.research.google.com/drive/1O7yIUOUuzK3us08oBmuCwmbCXi4rfsYd
